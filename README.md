# üîç Explicabilit√© en Intelligence Artificielle

<div align="center">

![XAI Banner](https://img.shields.io/badge/XAI-Explainable%20AI-blue)
![Python](https://img.shields.io/badge/Python-3.9%2B-brightgreen)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Status-Active-success)

</div>

## üìã Pr√©sentation

> Exploration et Tests de six m√©thodes d'explicabilit√© pour l'IA

## üìã M√©thodes test√©es :

![SHAP](https://img.shields.io/badge/SHAP-SHapley_Additive_exPlanations-blue) 

![DiCE](https://img.shields.io/badge/DiCE-Diverse_Counterfactual_Explanations-green) 

![GradCAM](https://img.shields.io/badge/GradCAM-Gradient_weighted_Class_Activation_Mapping-orange) 

![Captum](https://img.shields.io/badge/Captum-Library-red) 

![LRP](https://img.shields.io/badge/LRP-Layer_wise_Relevance_Propagation-purple)

> ‚§∑ ![Standard](https://img.shields.io/badge/Standard-Networks-lightgrey)

> ‚§∑ ![GNN](https://img.shields.io/badge/Graph-Neural_Networks-yellow)

## üéØ Introduction

L'**IA explicable (XAI)** est devenue un enjeu crucial dans le d√©veloppement des syst√®mes d'intelligence artificielle modernes. Notre travail se concentre sur la prise en main de m√©thodes d'explicabilit√© r√©centes et d'identifier leurs limites avec de nouvelles donn√©es.





## üéì Contenu

### 1Ô∏è‚É£ Rapport de pr√©sentation
- [x] Fondements th√©oriques
- [x] R√©sultats
- [x] Discussion

### 2Ô∏è‚É£ 6 notebooks
 - [x] SHAP
- [x] DiCE
- [x] GradCAM
 - [x] Librairie Captum
- [x] LRP en NN standards
- [x] LRP en GNN




---

<div align="center">

**Made with ‚ù§Ô∏è by Mehdi**

*Pour toute question ou suggestion, n'h√©sitez pas √† me contacter*

</div>
